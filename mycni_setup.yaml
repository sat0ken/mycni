apiVersion: v1
kind: ConfigMap
metadata:
  name: init-scripts
  namespace: kube-system
data:
  setup.sh: |
    #!/bin/bash
    apt update
    apt install -y curl iproute2 jq bridge-utils iptables >> /dev/null
    curl -s -LO "https://dl.k8s.io/release/$(curl -s -LS https://dl.k8s.io/release/stable.txt)/bin/linux/amd64/kubectl"
    chmod +x ./kubectl && mv ./kubectl /usr/local/bin

    # NodeのspecからCIDRを取得
    podCIDR=$(kubectl get node $(hostname) -o jsonpath='{.spec.podCIDR}')
    printf "%s podCIDR is %s\n" $(hostname) $podCIDR

    # linux-bridgeにセットするIPを生成
    bridge_ip=$(echo $podCIDR | sed -e "s|0/24|1/24|")

    # linux-bridgeを作成してIPアドレスを設定
    brctl addbr br0
    ip link set br0 up
    ip addr add $bridge_ip dev br0
    printf "create br0, set ipaddr %s\n" $bridge_ip

    # 外に出れるようにiptablesを設定
    cluster_cidr=$(echo $bridge_ip | sed -e "s/10.244.*/10.244.0.0\/16/")
    iptables -N mycni_firewall
    iptables -A FORWARD -p all -j mycni_firewall
    iptables -A INPUT -p all -j mycni_firewall
    iptables -A OUTPUT -p all -j mycni_firewall
    iptables -A FORWARD -s $cluster_cidr -j ACCEPT
    iptables -A FORWARD -d $cluster_cidr -j ACCEPT
    iptables -t nat -N KIND-MASQ-AGENT
    iptables -t nat -A POSTROUTING -m addrtype ! --dst-type LOCAL -j KIND-MASQ-AGENT
    iptables -t nat -A KIND-MASQ-AGENT -d $cluster_cidr -j RETURN
    iptables -t nat -A KIND-MASQ-AGENT -j MASQUERADE

    # 他のNodeのIPアドレスとPodCIDRを取得してip routeコマンドで静的ルートを設定
    nodes=($(kubectl get node -o json | jq .items | jq --arg arg $(hostname) -r '.[] | select(.metadata.name != $arg) .metadata.name'))
    for node in "${nodes[@]}"
    do
      node_ip=$(kubectl get node "${node}" -o jsonpath='{.status.addresses}' | jq -r '.[] | select(.type == "InternalIP") .address')
      pod_cidr=$(kubectl get node "${node}" -o jsonpath='{.spec.podCIDR}')
      printf "ip route add %s via %s dev eth0\n" $pod_cidr $node_ip
      ip route add $pod_cidr via $node_ip dev eth0
    done
    curl -LO https://raw.githubusercontent.com/sat0ken/mycni/master/mycni.conf && mv ./mycni.conf /etc/cni/net.d
    curl -LO https://raw.githubusercontent.com/sat0ken/mycni/master/mycni && chmod +x ./mycni && mv ./mycni /opt/cni/bin
    echo "mycni init successfully..."
---
apiVersion: v1
kind: ConfigMap
metadata:
  name: cleanup-scripts
  namespace: kube-system
data:
  cleanup.sh: |
    #!/bin/bash
    apt update
    apt install -y bridge-utils iptables iproute2
    ip link set br0 down
    brctl delbr br0
    rm -f /etc/cni/net.d/mycni.conf
    rm -f /opt/cni/bin/mycni
    ip link show | grep ": veth_host" | cut -d"@" -f1 | cut -d":" -f2 | xargs -I dev ip link del dev
    iptables -t filter -nvL --line-numbers | grep 10.244 | grep -o "^[0-9]" | head -n 1 | xargs -I num iptables -t filter -D FORWARD num
    iptables -t nat -nvL --line-numbers | grep br0 | grep -o "^[0-9]" | xargs -I num iptables -t nat -D POSTROUTING num
    echo "mycni cleanup successfully..."
---
apiVersion: v1
kind: ConfigMap
metadata:
  namespace: kube-system
  name: cleanup-netpol
data:
  netpol-clean.sh: |
    #!/bin/bash

    netpol_items=($(kubectl get networkpolicies.networking.k8s.io -A -o json | jq -c -r '.items[]'))

    length=${#netpol_items[@]}

    # filterのルール数を取得
    rules=$(iptables -t filter -L mycni_firewall | grep -v Chain | grep -v target | wc -l)

    # # NWポリシーが設定されていない状態でipsetとiptablesのルールが残っている場合は消去する
    if [[ "$length" -eq 0 ]]; then
      # 不要なルールを削除(他のルールも消しそうで危険)
      if [[ "$rules" -eq 0 ]]; then
        iptables -t filter -F mycni_firewall
      fi

      # IPセットのリストを取得
      ipset_list=$(ipset list -n)
      # IPセットが存在するかどうかを確認
      if [[ -n "$ipset_list" ]]; then
        # 各IPセットをループして削除
        for set_name in $ipset_list; do
          ipset flush "$set_name"
          ipset destroy "$set_name"
        done
      fi
    fi
---
apiVersion: v1
kind: ConfigMap
metadata:
  namespace: kube-system
  name: create-netpol
data:
  netpol.sh: |
    #!/bin/bash

    # ipsetを作成しPodのIPを登録する
    set_ipset_rules() {
      local set_ip_list=($1)
      local ipset_name=$2
      local ipset_type=$3

      # 存在しなければipsetのlistを新規作成
      stdout=$(ipset list | grep $ipset_name)
      if [ -z "$stdout" ]; then
        printf "ipset create %s %s\n" $ipset_name $ipset_type >> /tmp/cmd.sh
        for pod_ip in "${set_ip_list[@]}"
        do
            printf "ipset add %s %s\n" $ipset_name $pod_ip >> /tmp/cmd.sh
        done
      else
        # 既にルールがあったら更新処理をすべきだが対応していない
        printf "already exist ipset %s\n" $ipset_name
      fi
    }

    set_ingress_nw_policy_peer() {
      spec=$1
      nw_policy_peers=$2
      name=$(echo "$item" | jq -r .metadata.name)
      namespace=$(echo "$spec" | jq -r .metadata.namespace)
      allow_ipset_name=$(printf "%s-%s" $namespace $name)

      for peer in "${nw_policy_peers[@]}"
      do
        if [ $peer = "ipBlock" ]; then
            # ipBlockに対応していない
            :
        elif [ $peer = "namespaceSelector" ]; then
            # namespaceSelectorに対応していない
            :
        else
            allow_pod_label=$(echo "$spec" | jq -c '.spec.ingress[].from[].podSelector.matchLabels' | sed -e "s/{//" -e "s/}//" -e "s/\"//g" -e "s/:/=/")
            allow_pod_ips=($(kubectl -n $namespace get pod -l $allow_pod_label -o json | jq -r .items[].status.podIP))
            set_ipset_rules "${allow_pod_ips[*]}" $allow_ipset_name "hash:ip"
        fi
      done

      # 作成したipsetの名前を戻り値として返す
      echo $allow_ipset_name
    }

    set_ingress() {
      ingress_list=($(echo "$1" | jq -r '.spec.ingress[] | keys | .[]'))
      local allow_ipset_name

      for ingress in "${ingress_list[@]}"
      do
        if [ $ingress = "from" ]; then
          from=($(echo "$1" | jq -r .spec.ingress[] | jq -r '.from[] | keys | .[]'))
          allow_ipset_name=$(set_ingress_nw_policy_peer $1 $from)
        fi
      done

      # 作成したipsetの名前を戻り値として返す
      echo $allow_ipset_name
    }

    FILE=/tmp/cmd.sh
    if [ -f "$FILE" ]; then
      rm $FILE
    fi

    # mainの処理
    kubectl get networkpolicies.networking.k8s.io -A -o json | jq -c .items[] | while read -r item; do
      name=$(echo "$item" | jq -r .metadata.name)
      namespace=$(echo "$item" | jq -r .metadata.namespace)
      policy_types=($(echo "$item" | jq -r .spec.policyTypes[]))
      pod_labels=$(echo "$item" | jq -c '.spec.podSelector.matchLabels' | sed -e "s/{//" -e "s/}//" -e "s/\"//g" -e "s/:/=/")
      pod_ips=($(kubectl -n $namespace get pod -l $pod_labels -o json | jq -r .items[].status.podIP))
      ipset_type="hash:ip"

      # NW Polocyを設定する対象のPodのipsetを作成する
      target_ipset_name=$(printf "%s-%s-target" $namespace $name)
      set_ipset_rules "${pod_ips[*]}" $target_ipset_name $ipset_type

      for policy in "${policy_types[@]}"
      do
        # Ingressのみ対応している
        if [ $policy = "Ingress" ]; then
          allow_ipset_name=$(set_ingress $item)
          printf "iptables -A mycni_firewall --ipv4 -m set --match-set %s src -m set --match-set %s dst -j ACCEPT\n" $allow_ipset_name $target_ipset_name >> /tmp/cmd.sh
          printf "iptables -A mycni_firewall --ipv4 -m set ! --match-set %s src -m set --match-set %s dst -j DROP\n" $allow_ipset_name $target_ipset_name >> /tmp/cmd.sh
        else
            :
        fi
      done

      # ipsetとiptablesを設定
      bash /tmp/cmd.sh
    done
---
apiVersion: apps/v1
kind: DaemonSet
metadata:
  name: mycni
  namespace: kube-system
spec:
  selector:
    matchLabels:
      app: mycni
  template:
    metadata:
      creationTimestamp: null
      labels:
        app: mycni
    spec:
      initContainers:
        - image: ubuntu:22.04
          name: init
          command: ["/bin/bash", "/setup/setup.sh"]
          securityContext:
            privileged: true
          volumeMounts:
            - mountPath: /setup
              name: setup
            - mountPath: /cleanup
              name: cleanup
            - mountPath: /etc/cni/net.d
              name: cni-cfg
            - mountPath: /opt/cni/bin
              name: cni-bin
      containers:
        - image: ubuntu:22.04
          name: pause
          args:
            - sleep
            - infinity
          securityContext:
            privileged: true
          volumeMounts:
            - mountPath: /cleanup
              name: cleanup
            - mountPath: /netpol/create
              name: create-netpol
            - mountPath: /netpol/clean
              name: cleanup-netpol
          lifecycle:
            preStop:
              exec:
                command: ["/bin/bash", "/cleanup/cleanup.sh"]
      hostNetwork: true
      nodeSelector:
        kubernetes.io/os: linux
      schedulerName: default-scheduler
      serviceAccount: namespace-controller
      tolerations:
        - operator: Exists
      volumes:
        - name: setup
          configMap:
            name: init-scripts
            items:
              - key: setup.sh
                path: setup.sh
        - name: cleanup
          configMap:
            name: cleanup-scripts
            items:
              - key: cleanup.sh
                path: cleanup.sh
        - name: create-netpol
          configMap:
            name: create-netpol
            items:
              - key: netpol.sh
                path: netpol.sh
        - name: cleanup-netpol
          configMap:
            name: cleanup-netpol
            items:
              - key: netpol-clean.sh
                path: netpol-clean.sh
        - hostPath:
            path: /etc/cni/net.d
            type: ""
          name: cni-cfg
        - hostPath:
            path: /opt/cni/bin
            type: ""
          name: cni-bin
